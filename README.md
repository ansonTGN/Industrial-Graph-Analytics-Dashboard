# Neo4j Industrial Graph Dashboard
**AnalÃ­tica Avanzada de Activos Industriales con Rust + Neo4j + GenAI Multi-Proveedor**

![Rust](https://img.shields.io/badge/Rust-1.75%2B-orange?logo=rust)
![Neo4j](https://img.shields.io/badge/Neo4j-Aura%20%2F%20Local-blue?logo=neo4j)
![Actix-Web](https://img.shields.io/badge/Backend-Actix_Web-green)
![AI Providers](https://img.shields.io/badge/AI-OpenAI%20|%20Groq%20|%20DeepSeek%20|%20Ollama-purple?logo=openai)
![License](https://img.shields.io/badge/License-MIT-lightgrey)

---

**Idiomas / Languages / Idiomes:**  
[ğŸ‡ªğŸ‡¸ EspaÃ±ol](#-espaÃ±ol) | [ğŸ‡¬ğŸ‡§ English](#-english) | [ğŸ´ CatalÃ ](#-catalÃ )

---

<a name="-espaÃ±ol"></a>
# ğŸ‡ªğŸ‡¸ EspaÃ±ol

## ğŸ“– DescripciÃ³n General
**Neo4j Industrial Graph Dashboard** es una plataforma web de alto rendimiento diseÃ±ada para la visualizaciÃ³n, auditorÃ­a y anÃ¡lisis de activos industriales complejos. Su arquitectura combina la seguridad y velocidad de **Rust** en el backend con la potencia de **Neo4j** para modelar relaciones jerÃ¡rquicas (Plantas â†’ Equipos â†’ Materiales).

La caracterÃ­stica estrella es su **Asistente de IA Universal**, capaz de traducir preguntas en lenguaje natural a consultas Cypher complejas, soportando mÃºltiples proveedores de LLM (Nube y Local).

### âœ¨ CaracterÃ­sticas Principales
*   **VisualizaciÃ³n de Grafos:** Renderizado interactivo de redes de activos con `Vis.js`.
*   **GestiÃ³n DinÃ¡mica:** Las consultas se cargan desde un archivo JSON sin recompilar el servidor.
*   **Multi-Proveedor de IA:** Soporte nativo para OpenAI, Groq, DeepSeek y modelos locales con Ollama.
*   **Proxy Seguro:** El backend actÃºa como pasarela para evitar problemas de CORS y proteger las claves API.

---

## ğŸ¤– ConfiguraciÃ³n del Asistente de IA (Multi-Modelo)

La aplicaciÃ³n incluye un chat inteligente (botÃ³n flotante ğŸ¤–) que utiliza **Function Calling** para interrogar a la base de datos. Puedes elegir tu proveedor de IA preferido haciendo clic en el botÃ³n de configuraciÃ³n (âš™ï¸) dentro del chat.

### Opciones de ConfiguraciÃ³n

#### 1. âš¡ Groq (Recomendado por Velocidad)
Ideal para respuestas casi instantÃ¡neas utilizando modelos Llama 3.
*   **Proveedor:** Selecciona `Groq`.
*   **API Key:** ObtÃ©n una gratuita en [console.groq.com](https://console.groq.com).
*   **Modelo:** Por defecto usa `llama-3.3-70b-versatile`.

#### 2. ğŸ§  OpenAI (EstÃ¡ndar)
La opciÃ³n mÃ¡s robusta y fiable.
*   **Proveedor:** Selecciona `OpenAI`.
*   **API Key:** Tu clave `sk-...` de OpenAI.
*   **Modelo:** `gpt-4o` (por defecto).

#### 3. ğŸ’» Ollama (Privacidad Local)
Para ejecutar modelos en tu propia mÃ¡quina sin enviar datos a la nube.
*   **Proveedor:** Selecciona `Ollama`.
*   **Requisitos:** Tener [Ollama](https://ollama.com/) instalado.
*   **ConfiguraciÃ³n TÃ©cnica:**
    *   Ejecuta Ollama permitiendo orÃ­genes: `OLLAMA_ORIGINS="*" ollama serve`
    *   **Si usas Docker:** La URL debe ser `http://host.docker.internal:11434/v1/chat/completions`.
    *   **Si ejecutas en local:** La URL es `http://localhost:11434/v1/chat/completions`.
*   **Modelo:** AsegÃºrate de tener el modelo descargado (ej. `ollama pull llama3.2`).

#### 4. ğŸš€ DeepSeek (EconÃ³mico y Potente)
Excelente capacidad de razonamiento (V3) a una fracciÃ³n del coste.
*   **Proveedor:** Selecciona `DeepSeek`.
*   **API Key:** Tu clave de `platform.deepseek.com`.

#### 5. ğŸ”Œ Anthropic (Claude) / Custom
Para usar Claude 3.5 Sonnet u otros proveedores compatibles con OpenAI.
*   **Proveedor:** Selecciona `Custom`.
*   **MÃ©todo Recomendado:** Usar **OpenRouter** como intermediario para compatibilidad de API.
    *   **Base URL:** `https://openrouter.ai/api/v1/chat/completions`
    *   **Modelo:** `anthropic/claude-3.5-sonnet`

---

## ğŸ§© GestiÃ³n de Consultas (Queries)

No es necesario tocar cÃ³digo Rust para aÃ±adir nuevas analÃ­ticas. Todo reside en `queries.json`.

```json
{
  "id": "M01",
  "category": "Mantenimiento",
  "title": "Desglose BOM",
  "description": "DescripciÃ³n que la IA usa para entender cuÃ¡ndo usar esta herramienta.",
  "cypher": "MATCH (n)-[:REL]->(m) RETURN ...",
  "needs_param": true,  // true = Requiere seleccionar un nodo antes
  "is_graph": true,     // true = Renderiza nodos; false = Renderiza tabla/grÃ¡fico
  "icon": "fa-share-nodes"
}
```
*Para aÃ±adir una consulta, simplemente edita este archivo y reinicia el servidor.*

---

## ğŸš€ Despliegue

### Docker (Recomendado)
```bash
# Construir la imagen
docker build -t neo4j_dashboard .

# Ejecutar (AsegÃºrate de tener el archivo .env configurado)
docker run -p 8080:8080 --env-file .env neo4j_dashboard
```

### EjecuciÃ³n Local (Rust)
```bash
# Instalar dependencias
cargo build --release

# Ejecutar
./target/release/neo4j_dashboard
```

Variables de entorno requeridas en `.env`:
```env
NEO4J_URI="neo4j+s://<tu-instancia>.databases.neo4j.io"
NEO4J_USERNAME="neo4j"
NEO4J_PASSWORD="<tu-password>"
PORT=8080
```

---

<a name="-english"></a>
# ğŸ‡¬ğŸ‡§ English

## ğŸ“– Overview
**Neo4j Industrial Graph Dashboard** is a high-performance web platform designed for visualization, auditing, and analysis of complex industrial assets. Its architecture combines the safety and speed of **Rust** on the backend with the power of **Neo4j** to model hierarchical relationships (Plants â†’ Equipment â†’ Materials).

The flagship feature is its **Universal AI Assistant**, capable of translating natural language questions into complex Cypher queries, supporting multiple LLM providers (Cloud & Local).

### âœ¨ Key Features
*   **Graph Visualization:** Interactive asset network rendering with `Vis.js`.
*   **Dynamic Management:** Queries are loaded from a JSON file without recompiling the server.
*   **Multi-Provider AI:** Native support for OpenAI, Groq, DeepSeek, and local models via Ollama.
*   **Secure Proxy:** The backend acts as a gateway to prevent CORS issues and protect API keys.

---

## ğŸ¤– AI Assistant Configuration (Multi-Model)

The application includes a smart chat (floating button ğŸ¤–) that uses **Function Calling** to query the database. You can choose your preferred AI provider by clicking the settings button (âš™ï¸) inside the chat.

### Configuration Options

#### 1. âš¡ Groq (Recommended for Speed)
Ideal for near-instant responses using Llama 3 models.
*   **Provider:** Select `Groq`.
*   **API Key:** Get a free one at [console.groq.com](https://console.groq.com).
*   **Model:** Defaults to `llama-3.3-70b-versatile`.

#### 2. ğŸ§  OpenAI (Standard)
The most robust and reliable option.
*   **Provider:** Select `OpenAI`.
*   **API Key:** Your OpenAI `sk-...` key.
*   **Model:** `gpt-4o` (default).

#### 3. ğŸ’» Ollama (Local Privacy)
To run models on your own machine without sending data to the cloud.
*   **Provider:** Select `Ollama`.
*   **Requirements:** Have [Ollama](https://ollama.com/) installed.
*   **Technical Setup:**
    *   Run Ollama allowing origins: `OLLAMA_ORIGINS="*" ollama serve`
    *   **If using Docker:** URL must be `http://host.docker.internal:11434/v1/chat/completions`.
    *   **If running locally:** URL is `http://localhost:11434/v1/chat/completions`.
*   **Model:** Ensure you have pulled the model (e.g., `ollama pull llama3.2`).

#### 4. ğŸš€ DeepSeek (Cost-Effective & Powerful)
Excellent reasoning capabilities (V3) at a fraction of the cost.
*   **Provider:** Select `DeepSeek`.
*   **API Key:** Your key from `platform.deepseek.com`.

#### 5. ğŸ”Œ Anthropic (Claude) / Custom
To use Claude 3.5 Sonnet or other OpenAI-compatible providers.
*   **Provider:** Select `Custom`.
*   **Recommended Method:** Use **OpenRouter** as a middleware for API compatibility.
    *   **Base URL:** `https://openrouter.ai/api/v1/chat/completions`
    *   **Model:** `anthropic/claude-3.5-sonnet`

---

## ğŸ§© Query Management

No need to touch Rust code to add new analytics. Everything resides in `queries.json`.

```json
{
  "id": "M01",
  "category": "Maintenance",
  "title": "BOM Breakdown",
  "description": "Description the AI uses to understand when to use this tool.",
  "cypher": "MATCH (n)-[:REL]->(m) RETURN ...",
  "needs_param": true,  // true = Requires selecting a node first
  "is_graph": true,     // true = Renders nodes; false = Renders table/chart
  "icon": "fa-share-nodes"
}
```
*To add a query, simply edit this file and restart the server.*

---

## ğŸš€ Deployment

### Docker (Recommended)
```bash
# Build the image
docker build -t neo4j_dashboard .

# Run (Ensure you have the .env file configured)
docker run -p 8080:8080 --env-file .env neo4j_dashboard
```

### Local Execution (Rust)
```bash
# Install dependencies & Build
cargo build --release

# Run
./target/release/neo4j_dashboard
```

Required environment variables in `.env`:
```env
NEO4J_URI="neo4j+s://<your-instance>.databases.neo4j.io"
NEO4J_USERNAME="neo4j"
NEO4J_PASSWORD="<your-password>"
PORT=8080
```

---

<a name="-catalÃ "></a>
# ğŸ´ CatalÃ 

## ğŸ“– DescripciÃ³ General
**Neo4j Industrial Graph Dashboard** Ã©s una plataforma web d'alt rendiment dissenyada per a la visualitzaciÃ³, auditoria i anÃ lisi d'actius industrials complexos. La seva arquitectura combina la seguretat i velocitat de **Rust** al backend amb la potÃ¨ncia de **Neo4j** per modelar relacions jerÃ rquiques (Plantes â†’ Equips â†’ Materials).

La caracterÃ­stica estrella Ã©s el seu **Assistent d'IA Universal**, capaÃ§ de traduir preguntes en llenguatge natural a consultes Cypher complexes, suportant mÃºltiples proveÃ¯dors de LLM (NÃºvol i Local).

### âœ¨ CaracterÃ­stiques Principals
*   **VisualitzaciÃ³ de Grafs:** RenderitzaciÃ³ interactiva de xarxes d'actius amb `Vis.js`.
*   **GestiÃ³ DinÃ mica:** Les consultes es carreguen des d'un fitxer JSON sense recompilar el servidor.
*   **Multi-ProveÃ¯dor d'IA:** Suport natiu per a OpenAI, Groq, DeepSeek i models locals amb Ollama.
*   **Proxy Segur:** El backend actua com a passarelÂ·la per evitar problemes de CORS i protegir les claus API.

---

## ğŸ¤– ConfiguraciÃ³ de l'Assistent d'IA (Multi-Model)

L'aplicaciÃ³ inclou un xat intelÂ·ligent (botÃ³ flotant ğŸ¤–) que utilitza **Function Calling** per interrogar la base de dades. Pots triar el teu proveÃ¯dor d'IA preferit fent clic al botÃ³ de configuraciÃ³ (âš™ï¸) dins del xat.

### Opcions de ConfiguraciÃ³

#### 1. âš¡ Groq (Recomanat per Velocitat)
Ideal per a respostes gairebÃ© instantÃ nies utilitzant models Llama 3.
*   **ProveÃ¯dor:** Selecciona `Groq`.
*   **API Key:** Aconsegueix-ne una gratuÃ¯ta a [console.groq.com](https://console.groq.com).
*   **Model:** Per defecte utilitza `llama-3.3-70b-versatile`.

#### 2. ğŸ§  OpenAI (EstÃ ndard)
L'opciÃ³ mÃ©s robusta i fiable.
*   **ProveÃ¯dor:** Selecciona `OpenAI`.
*   **API Key:** La teva clau `sk-...` d'OpenAI.
*   **Model:** `gpt-4o` (per defecte).

#### 3. ğŸ’» Ollama (Privadesa Local)
Per executar models a la teva prÃ²pia mÃ quina sense enviar dades al nÃºvol.
*   **ProveÃ¯dor:** Selecciona `Ollama`.
*   **Requisits:** Tenir [Ollama](https://ollama.com/) instalÂ·lat.
*   **ConfiguraciÃ³ TÃ¨cnica:**
    *   Executa Ollama permetent orÃ­gens: `OLLAMA_ORIGINS="*" ollama serve`
    *   **Si utilitzes Docker:** La URL ha de ser `http://host.docker.internal:11434/v1/chat/completions`.
    *   **Si executes en local:** La URL Ã©s `http://localhost:11434/v1/chat/completions`.
*   **Model:** Assegura't de tenir el model descarregat (ex. `ollama pull llama3.2`).

#### 4. ğŸš€ DeepSeek (EconÃ²mic i Potent)
ExcelÂ·lent capacitat de raonament (V3) a una fracciÃ³ del cost.
*   **ProveÃ¯dor:** Selecciona `DeepSeek`.
*   **API Key:** La teva clau de `platform.deepseek.com`.

#### 5. ğŸ”Œ Anthropic (Claude) / Custom
Per utilitzar Claude 3.5 Sonnet o altres proveÃ¯dors compatibles amb OpenAI.
*   **ProveÃ¯dor:** Selecciona `Custom`.
*   **MÃ¨tode Recomanat:** Utilitzar **OpenRouter** com a intermediari per a compatibilitat d'API.
    *   **Base URL:** `https://openrouter.ai/api/v1/chat/completions`
    *   **Model:** `anthropic/claude-3.5-sonnet`

---

## ğŸ§© GestiÃ³ de Consultes (Queries)

No cal tocar codi Rust per afegir noves analÃ­tiques. Tot resideix a `queries.json`.

```json
{
  "id": "M01",
  "category": "Manteniment",
  "title": "Desglossament BOM",
  "description": "DescripciÃ³ que la IA utilitza per entendre quan fer servir aquesta eina.",
  "cypher": "MATCH (n)-[:REL]->(m) RETURN ...",
  "needs_param": true,  // true = Requereix seleccionar un node abans
  "is_graph": true,     // true = Renderitza nodes; false = Renderitza taula/grÃ fic
  "icon": "fa-share-nodes"
}
```
*Per afegir una consulta, simplement edita aquest fitxer i reinicia el servidor.*

---

## ğŸš€ Desplegament

### Docker (Recomanat)
```bash
# Construir la imatge
docker build -t neo4j_dashboard .

# Executar (Assegura't de tenir el fitxer .env configurat)
docker run -p 8080:8080 --env-file .env neo4j_dashboard
```

### ExecuciÃ³ Local (Rust)
```bash
# InstalÂ·lar dependÃ¨ncies i compilar
cargo build --release

# Executar
./target/release/neo4j_dashboard
```

Variables d'entorn requerides a `.env`:
```env
NEO4J_URI="neo4j+s://<la-teva-instancia>.databases.neo4j.io"
NEO4J_USERNAME="neo4j"
NEO4J_PASSWORD="<el-teu-password>"
PORT=8080
```

---

### Author / Autor
**Angel A. Urbina**  
ğŸ“§ [CV & Portfolio](https://angelurbinacv.netlify.app/)

### License
This project is licensed under the MIT License.
